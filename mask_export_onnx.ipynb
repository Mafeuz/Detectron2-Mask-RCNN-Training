{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MM-ePp1yT8e2"
   },
   "source": [
    "### Preparing the dataset\n",
    "\n",
    "Prepare the dataset using Labelme annotation tool (for Instance segmentation) and LabelImg for object detection.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YTV4jWZMYMlu"
   },
   "source": [
    "### Installing Detectron2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gcc (Ubuntu 9.4.0-1ubuntu1~20.04.1) 9.4.0\r\n",
      "Copyright (C) 2019 Free Software Foundation, Inc.\r\n",
      "This is free software; see the source for copying conditions.  There is NO\r\n",
      "warranty; not even for MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.\r\n",
      "\r\n"
     ]
    }
   ],
   "source": [
    "# install dependencies: \n",
    "#!pip install pyyaml==5.1\n",
    "#!pip install onnx==1.8.0\n",
    "\n",
    "#!pip install pyyaml==5.1\n",
    "#!pip install torch==1.8.0+cu101 torchvision==0.9.0+cu101 -f https://download.pytorch.org/whl/torch_stable.html\n",
    "\n",
    "#!pip install detectron2 -f https://dl.fbaipublicfiles.com/detectron2/wheels/cu101/torch1.8/index.html\n",
    "\n",
    "!gcc --version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Export Model to ONNX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import detectron2\n",
    "import onnx\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "# import some common detectron2 utilities\n",
    "from detectron2 import model_zoo\n",
    "from detectron2.config import get_cfg\n",
    "from detectron2.export import export_onnx_model, export_caffe2_model\n",
    "from detectron2.modeling import build_model\n",
    "from detectron2.checkpoint import DetectionCheckpointer\n",
    "import detectron2.data.transforms as T\n",
    "\n",
    "# From Module:\n",
    "from mask_inference import load_maskrcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onnx_export(model_path, classes_list, conf_thresh, img_size, save_name):\n",
    "    \n",
    "    '''\n",
    "        Method for converting .pt detectron2 mask-rcnn model to onnx\n",
    "    '''\n",
    "    \n",
    "    print('Loading Model...')\n",
    "    cfg, _, _ = load_maskrcnn(model_path, classes_list, conf_thresh)\n",
    "\n",
    "    model = build_model(cfg)\n",
    "    model.eval()\n",
    "    checkpointer = DetectionCheckpointer(model)\n",
    "    checkpointer.load(cfg.MODEL.WEIGHTS)\n",
    "    aug = T.ResizeShortestEdge([cfg.INPUT.MIN_SIZE_TEST, cfg.INPUT.MIN_SIZE_TEST],\n",
    "                               cfg.INPUT.MAX_SIZE_TEST)\n",
    "\n",
    "    print('Min Input:', cfg.INPUT.MIN_SIZE_TEST)\n",
    "    print('Max Input:', cfg.INPUT.MAX_SIZE_TEST)\n",
    "    \n",
    "    height, width, channels = img_size\n",
    "    \n",
    "    print('Collecting valid input img:')\n",
    "    !wget http://images.cocodataset.org/val2017/000000439715.jpg -q -O input.jpg\n",
    "    img = cv2.imread(\"./input.jpg\")\n",
    "    \n",
    "    image = aug.get_transform(img).apply_image(img)\n",
    "    image = torch.as_tensor(image.astype(\"float32\").transpose(2, 0, 1))\n",
    "    inputs = {\"image\": image, \"height\": height, \"width\": width}\n",
    "    \n",
    "    # Export to Onnx model\n",
    "    print('Exporting model to onnx...')\n",
    "    onnxModel = export_onnx_model(cfg, model, [inputs])\n",
    "    onnx.save(onnxModel, f'{save_name}.onnx')\n",
    "    print('Process completed, model onnx available!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Model...\n",
      "Min Input: 800\n",
      "Max Input: 1333\n",
      "Collecting valid input img:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "export_caffe2_model() is deprecated. Please use `Caffe2Tracer().export_onnx() instead.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exporting model to onnx...\n",
      "WARNING: ONNX Optimizer has been moved to https://github.com/onnx/optimizer.\n",
      "All further enhancements and fixes to optimizers will be done in this new repo.\n",
      "The optimizer code in onnx/onnx repo will be removed in 1.9 release.\n",
      "\n",
      "Process completed, model onnx available!\n"
     ]
    }
   ],
   "source": [
    "model_path   = '/home/autaza/Documentos/detectron_2_venv/fringe_segmentation.pth'\n",
    "classes_list = ['fringe']\n",
    "conf_thresh  = 0.5\n",
    "img_size     = (2000, 2000, 3)\n",
    "save_name    = 'fringe_seg'\n",
    "\n",
    "onnx_export(model_path, classes_list, conf_thresh, img_size, save_name)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Train Detectron2 on custom dataset.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
